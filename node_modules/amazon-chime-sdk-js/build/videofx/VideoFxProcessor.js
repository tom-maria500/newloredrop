"use strict";
// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
// SPDX-License-Identifier: Apache-2.0
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const fetch_1 = require("../../libs/voicefocus/fetch");
const loader_1 = require("../../libs/voicefocus/loader");
const support_1 = require("../../libs/voicefocus/support");
const DefaultBrowserBehavior_1 = __importDefault(require("../browserbehavior/DefaultBrowserBehavior"));
const NoOpLogger_1 = __importDefault(require("../logger/NoOpLogger"));
const Utils_1 = require("../utils/Utils");
const Versioning_1 = __importDefault(require("../versioning/Versioning"));
const CanvasVideoFrameBuffer_1 = __importDefault(require("../videoframeprocessor/CanvasVideoFrameBuffer"));
const DeferredPromise_1 = require("./DeferredPromise");
const VideoFxCanvasOpsManager_1 = require("./VideoFxCanvasOpsManager");
const VideoFxConstants_1 = require("./VideoFxConstants");
const VideoFxSegmentationRateManager_1 = require("./VideoFxSegmentationRateManager");
/**
 * [[VideoFxProcessor]] Mechanism that drives the data transformation
 * of individual video frames to apply ML-based background blur and
 * background replacement effects on the video stream.
 */
class VideoFxProcessor {
    /**
     * Initializes a new instance of [[VideoFxProcessor]] with a default NoOp [[VideoFxConfig]].
     * @param logger
     * @param processingBudgetPerFrame throttling constraint for processing
     * @param eventController EventController object to manage events
     */
    constructor(logger, processingBudgetPerFrame = VideoFxConstants_1.RESOURCE_CONSTRAINTS.DEFAULT_PROCESSING_BUDGET_PER_FRAME, eventController) {
        this.logger = logger;
        // Configure the buffer for where output frames will be placed
        this.outputCanvas = document.createElement('canvas');
        this.canvasVideoFrameBuffer = new CanvasVideoFrameBuffer_1.default(this.outputCanvas);
        this.videoFxSpec = VideoFxConstants_1.DEFAULT_VIDEO_FX_SPEC;
        // Validate the inputted resource constraint
        try {
            this.validateProcessingBudgetPerFrame(processingBudgetPerFrame);
        }
        catch (error) {
            this.logger.error(error);
            throw new Error(`Cannot instantiate VideoFxProcessor due to invalid ` +
                `processingBudgetPerFrame of ${processingBudgetPerFrame}`);
        }
        if (eventController) {
            this.eventController = eventController;
        }
        // Create a basic effectConfig (noOp)
        this.effectConfig = {
            backgroundBlur: {
                isEnabled: false,
                strength: 'low',
            },
            backgroundReplacement: {
                isEnabled: false,
                backgroundImageURL: null,
                defaultColor: 'black',
            },
        };
        // This promise object will be used to coordinate timing of sending/receiving frames from engine
        this.segmentationRequestPromise = new DeferredPromise_1.DeferredPromise();
        // Configure resource management for the segmentation frequency
        this.segmentationRateManager = new VideoFxSegmentationRateManager_1.VideoFxSegmentationRateManager(this.logger, processingBudgetPerFrame);
        // Configure default streamParameters
        this.streamParameters = {
            framerate: VideoFxConstants_1.DEFAULT_STREAM_PARAMETERS.FRAMES_PER_SECOND,
            width: VideoFxConstants_1.DEFAULT_STREAM_PARAMETERS.WIDTH_IN_PIXEL,
            height: VideoFxConstants_1.DEFAULT_STREAM_PARAMETERS.HEIGHT_IN_PIXEL,
            channels: VideoFxConstants_1.DEFAULT_STREAM_PARAMETERS.CHANNEL_COUNT,
        };
        // Determine if shared array buffer can be used to transfer frame data from
        // main thread to web worker thread
        if (VideoFxProcessor.isSharedArrayBufferSupported) {
            this.sharedImageBuffer = new SharedArrayBuffer(VideoFxConstants_1.SEGMENTATION_MODEL.WIDTH_IN_PIXELS *
                VideoFxConstants_1.SEGMENTATION_MODEL.HEIGHT_IN_PIXELS *
                this.streamParameters.channels);
            this.sharedImageData = new Uint8ClampedArray(this.sharedImageBuffer);
        }
        this.logger.info(`VideoFx supports Shared Array Buffer: ` + `${VideoFxProcessor.isSharedArrayBufferSupported}`);
        // Determine if filter operations are supported
        this.canvasOpsManager = new VideoFxCanvasOpsManager_1.VideoFxCanvasOpsManager(this.streamParameters, this.outputCanvas);
        // Configure the final transformed frame location
        this.outputCanvas.width = this.streamParameters.width;
        this.outputCanvas.height = this.streamParameters.height;
        // Set an empty mask at initialization
        this.segmentationMask = new ImageData(this.streamParameters.width, this.streamParameters.height);
        this.logger.info(`VideoFxProcessor instantiated with a processingBudgetPerFrame of ${processingBudgetPerFrame}`);
    }
    /**
     * Apply the [[VideoFxProcessor]]'s specialized effect onto the frame contained by
     * the buffer parameter.
     * @param buffers
     * @returns buffers
     */
    process(buffers) {
        return __awaiter(this, void 0, void 0, function* () {
            // Note: Required method through implementation of VideoFrameProcessor.
            return buffers;
        });
    }
    /**
     * Process an input stream and apply the visual effects specified in this effectConfig.
     * @param buffers the input stream
     * @returns an output stream of VideoFrameBuffer
     */
    fxProcess(buffers) {
        return __awaiter(this, void 0, void 0, function* () {
            // Process our input image into raw input data
            const inputCanvas = buffers[0].asCanvasElement();
            // We must confirm that our incoming stream did not change it's parameters
            if (this.didStreamParametersChange(inputCanvas)) {
                yield this.adjustProcessorForNewStreamParameters(inputCanvas);
            }
            // Decide to use the existing segmentation or perform a new segmentation
            try {
                yield this.manageSegmentationMask(inputCanvas);
            }
            catch (error) {
                this.logger.error(error);
                throw new Error(`Video stream could not be processed`);
            }
            // Render a final image using the input canvas and the segmentation mask
            yield this.renderer.render(inputCanvas, this.segmentationMask);
            // Send canvas video frame buffer to rest of processor pipeline
            buffers[0] = this.canvasVideoFrameBuffer;
            return buffers;
        });
    }
    /**
     * Perform a process call that just returns the input stream
     * @param buffers the input stream
     * @returns an output stream of VideoFrameBuffer
     */
    noOpProcess(buffers) {
        return __awaiter(this, void 0, void 0, function* () {
            return buffers;
        });
    }
    /**
     * Check if the stream dimensions/parameters have changed.
     * @param stream frame from current video stream about to be processed
     * @returns boolean representing if the stream parameters changed
     */
    didStreamParametersChange(stream) {
        return (stream.width !== this.streamParameters.width || stream.height !== this.streamParameters.height);
    }
    /**
     * Adjust the videoFxProcessor to handle new stream parameters.
     * @param stream frame from current video stream about to be processed
     */
    adjustProcessorForNewStreamParameters(stream) {
        return __awaiter(this, void 0, void 0, function* () {
            // Update the stored streamParameters
            this.streamParameters.width = stream.width;
            this.streamParameters.height = stream.height;
            // Notify the canvas ops manager to reconfigure pipeline dimensions
            yield this.canvasOpsManager.configureForStreamParameters(this.streamParameters);
            // Configure the renderer to work with new stream dimensions
            yield this.renderer.configure(this.streamParameters.width, this.streamParameters.height, this.effectConfig);
        });
    }
    /**
     * Clean up any excess memory that has been allocated by [[VideoFxProcessor]].
     */
    destroy() {
        return __awaiter(this, void 0, void 0, function* () {
            // Note: Required method through implementation of VideoFrameProcessor.
            this.canvasVideoFrameBuffer.destroy();
            if (this.fxLibScript && this.fxLibScript.parentNode) {
                this.fxLibScript.parentNode.removeChild(this.fxLibScript);
            }
            if (this.engineWorker) {
                // Post message to destroy all assets
                this.destroyedAssetsPromise = new DeferredPromise_1.DeferredPromise();
                this.engineWorker.postMessage({
                    msg: VideoFxConstants_1.WORKER_MSG.DESTROY_ASSETS_REQUEST,
                });
                // Wait until all the assets are destroyed
                yield this.destroyedAssetsPromise.getPromise();
                // Close the engine worker
                this.engineWorker.postMessage({
                    msg: VideoFxConstants_1.WORKER_MSG.CLOSE_WORKER_REQUEST,
                });
            }
            this.logger.info(`VideoFxProcessor destroyed.`);
        });
    }
    /**
     * Manage the segmentation mask that is used to generate a final frame. This function
     * will calculate whether or not to re-generate a segmenation and also monitor
     * how computationally expensive the rate of segmentation are.
     * @param inputCanvas canvas to be used for segmentation
     */
    manageSegmentationMask(inputCanvas) {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                this.segmentationRateManager.submitFrame();
                if (this.segmentationRateManager.shouldApplySegmentation()) {
                    // Perform a segmentation inference on the downsampled current video frame
                    this.segmentationRateManager.startSegmentation();
                    const inferenceInputImageData = this.canvasOpsManager.getInferenceInputData(inputCanvas);
                    this.segmentationMask = yield this.generateSegmentationMask(inferenceInputImageData);
                    this.segmentationRateManager.completeSegmentation();
                }
            }
            catch (error) {
                this.logger.error(error.toString());
                throw new Error(`Can not properly manage the returned segmentation mask`);
            }
        });
    }
    /**
     * Generate a segmentation mask from the input frame.
     * @param inferenceImageData
     * @returns image data representing segmenation mask
     */
    generateSegmentationMask(inferenceImageData) {
        return __awaiter(this, void 0, void 0, function* () {
            if (VideoFxProcessor.isSharedArrayBufferSupported) {
                this.sharedImageData.set(inferenceImageData.data);
                this.engineWorker.postMessage({
                    msg: VideoFxConstants_1.WORKER_MSG.PERFORM_SEGMENTATION_SAB_REQUEST,
                    payload: this.sharedImageBuffer,
                });
            }
            else {
                this.engineWorker.postMessage({
                    msg: VideoFxConstants_1.WORKER_MSG.PERFORM_SEGMENTATION_REQUEST,
                    payload: inferenceImageData,
                }, [inferenceImageData.data.buffer]);
            }
            // Wait for input image to be returned from VideoFxEngine
            try {
                const segmentationMask = yield this.segmentationRequestPromise.getPromise();
                return segmentationMask;
            }
            catch (error) {
                this.logger.error(error.toString());
                throw new Error(`Segmentation mask could not be generated`);
            }
        });
    }
    /**
     * Make a deep copy of the VideoFxConfig passed in. Needs to be updated if additional
     * fields are added to VideoFxConfig.
     * @param effectConfig
     * @returns newEffectConfig
     */
    cloneConfigFrom(effectConfig) {
        return {
            backgroundBlur: {
                isEnabled: effectConfig.backgroundBlur.isEnabled,
                strength: effectConfig.backgroundBlur.strength,
            },
            backgroundReplacement: {
                isEnabled: effectConfig.backgroundReplacement.isEnabled,
                backgroundImageURL: effectConfig.backgroundReplacement.backgroundImageURL,
                defaultColor: effectConfig.backgroundReplacement.defaultColor,
            },
        };
    }
    setVideoFxSpec(videoFxSpec) {
        if (videoFxSpec.paths) {
            this.videoFxSpec.paths = videoFxSpec.paths;
        }
    }
    /**
     * Update the [[VideoFxProcessor]] to apply a new set of effects by updating the instance property
     * [[VideoFxConfig]]. If the effectConfig parameter fails validation, an error is thrown and there is
     * no update.
     * @Param effectConfig updated [[VideoFxConfig]] with new video effects
     */
    setEffectConfig(effectConfig) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.sameVideoFxConfig(effectConfig, this.effectConfig)) {
                return;
            }
            const newEffectConfig = this.cloneConfigFrom(effectConfig);
            // Validate the effect config
            try {
                yield this.validateEffectConfig(newEffectConfig);
            }
            catch (error) {
                this.logger.error(error.toString());
                throw new Error(`Provided effect config is invalid, not updating VideoFxProcessor`);
            }
            // Configure background replacement image/canvas
            if (newEffectConfig.backgroundReplacement.isEnabled) {
                yield this.canvasOpsManager.loadReplacementBackground(newEffectConfig);
                yield this.renderer.setBackgroundReplacementCanvas(this.canvasOpsManager.getBackgroundReplacementCanvas());
            }
            // Configure the renderer to implement the desired effect configuration
            yield this.renderer.configure(this.streamParameters.width, this.streamParameters.height, newEffectConfig);
            // Can now officially set the effect config since the rest of the processor is
            // configured for the new effects
            this.effectConfig = newEffectConfig;
            // If no effects are enabled, run no op process, otherwise run the effect based processing
            if (!this.effectConfig.backgroundBlur.isEnabled &&
                !this.effectConfig.backgroundReplacement.isEnabled) {
                this.process = this.noOpProcess;
            }
            else {
                this.process = this.fxProcess;
            }
            this.logger.info(`VideoFxProcessor effect configuration updated to: ${JSON.stringify(this.effectConfig)}`);
            if (this.eventController) {
                this.publishVideoFxConfigEvent();
            }
        });
    }
    /**
     * Confirm that the config consists of valid values.
     * @param config that will be validated
     */
    validateEffectConfig(config) {
        return __awaiter(this, void 0, void 0, function* () {
            // We confirm that both blur and replacement are not enabled due to builder error
            if (config.backgroundBlur.isEnabled && config.backgroundReplacement.isEnabled) {
                throw new Error(`Invalid VideoFx configuration: Background Blur and Background Replacement ` +
                    `can not both be enabled`);
            }
            else if (config.backgroundReplacement.isEnabled) {
                yield this.validateReplacementConfig(config);
            }
            // backgroundBlur does not need to be validated, as valid blurStrength value
            // is checked at compile time.
        });
    }
    /**
     * Confirm that the config consists of valid values for background replacement.
     * @param config that will be validated for background replacement
     */
    validateReplacementConfig(config) {
        return __awaiter(this, void 0, void 0, function* () {
            if (config.backgroundReplacement.backgroundImageURL &&
                config.backgroundReplacement.defaultColor) {
                throw new Error(`Invalid VideoFx configuration: Background Replacement can not have both an ` +
                    `image URL and default color`);
            }
            if (!config.backgroundReplacement.backgroundImageURL &&
                !config.backgroundReplacement.defaultColor) {
                throw new Error(`Invalid VideoFx configuration: Background Replacement image URL and default ` +
                    `can not both be null/undefined`);
            }
            // Confirm that the image properly loads
            try {
                if (config.backgroundReplacement.backgroundImageURL) {
                    yield this.canvasOpsManager.loadImage(config.backgroundReplacement.backgroundImageURL);
                }
            }
            catch (error) {
                this.logger.error(error.toString());
                throw new Error(`Invalid VideoFx configuration: backgroundImageURL failed to load`);
            }
            const defaultColor = config.backgroundReplacement.defaultColor;
            // Confirm that defaultColor is a valid color for fillStyle. We support black by default.
            if (defaultColor &&
                defaultColor !== 'black' &&
                defaultColor !== '#000000' &&
                defaultColor !== '#000') {
                // First validate hexadecimal color code
                if (defaultColor.includes('#')) {
                    const hexRegex = new RegExp(/^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})$/);
                    if (!hexRegex.test(defaultColor)) {
                        throw new Error(`Invalid hexadecimal color code for default replacement ` +
                            `background: ${defaultColor}`);
                    }
                }
                const testColorCanvas = document.createElement('canvas');
                const testColorCtx = testColorCanvas.getContext('2d');
                // fillStyle is #000000 black by default
                const prevFillStyle = testColorCtx.fillStyle;
                testColorCtx.fillStyle = defaultColor;
                // fillStyle will not change after assignment if invalid value is used
                /* istanbul ignore next */
                if (testColorCtx.fillStyle === prevFillStyle) {
                    throw new Error(`Invalid color for default replacement background: ${defaultColor}`);
                }
            }
        });
    }
    /**
     * Confirm that the processingBudgePerFrame constraint holds valid values.
     * @param constraint to be validated
     */
    validateProcessingBudgetPerFrame(processingBudgetPerFrame) {
        if (processingBudgetPerFrame < VideoFxConstants_1.RESOURCE_CONSTRAINTS.MIN_PROCESSING_BUDGET ||
            processingBudgetPerFrame > VideoFxConstants_1.RESOURCE_CONSTRAINTS.MAX_PROCESSING_BUDGET) {
            throw new Error(`Invalid resource constraint: cycle percentage must be within ` +
                `range of ${VideoFxConstants_1.RESOURCE_CONSTRAINTS.MIN_PROCESSING_BUDGET} and ` +
                `${VideoFxConstants_1.RESOURCE_CONSTRAINTS.MAX_PROCESSING_BUDGET}`);
        }
    }
    /**
     * Loads all of the assets that are associated with the stored effectConfig.
     */
    loadAssets() {
        return __awaiter(this, void 0, void 0, function* () {
            this.logger.info(`Loading required assets for the VideoFxProcessor`);
            try {
                const videoFxAssetParams = this.getVideoFxAssetParams();
                yield this.loadEngineWorker(videoFxAssetParams);
                yield this.buildEngine(videoFxAssetParams);
                yield this.loadFxLib(videoFxAssetParams);
                // @ts-ignore
                this.renderer = constructRenderer(VideoFxConstants_1.SEGMENTATION_MODEL.WIDTH_IN_PIXELS, VideoFxConstants_1.SEGMENTATION_MODEL.HEIGHT_IN_PIXELS, this.effectConfig, this.outputCanvas);
            }
            catch (error) {
                // NOTE: when we update to es2022, throw errors that are chained together
                this.logger.error(error.toString());
                throw new Error(`Failed to load necessary assets for the VideoFxProcessor`);
            }
            this.logger.info(`Finished loading of essential VideoFxProcessor assets.`);
        });
    }
    /**
     * Determines the current set of specifications that define the current SDK version.
     * @returns an [[VideoFxAssetParams]] object defining the parameters of the
     * current SDK
     */
    getVideoFxAssetParams() {
        const defaultAssetSpec = Utils_1.getDefaultAssetSpec();
        const videoFxAssetParams = {
            assetGroup: defaultAssetSpec.assetGroup,
            revisionID: defaultAssetSpec.revisionID,
            sdk: encodeURIComponent(Versioning_1.default.sdkVersion),
            ua: encodeURIComponent(Versioning_1.default.sdkUserAgentLowResolution),
        };
        return videoFxAssetParams;
    }
    /**
     * Generate a final path to an asset belonging to current version of SDK.
     * @param basePath Base of the path that will be used to generate a final path
     * @param videoFxAssetParams Parameters of the current SDK version
     * @returns A final path specific to an asset belonging to current SDK
     * version
     */
    getPathFromVideoFxAssetParams(basePath, videoFxAssetParams) {
        const path = new URL(basePath);
        for (const [key, value] of Object.entries(videoFxAssetParams)) {
            if (value !== undefined) {
                // Encode the key and value into uri format
                const uriEncodedKey = encodeURIComponent(key);
                const uriEncodedValue = encodeURIComponent(value);
                // Set encoded key/value as query params
                path.searchParams.set(uriEncodedKey, uriEncodedValue);
            }
        }
        return path.toString();
    }
    /**
     * Fetch and then load the engine worker into a web-worker.
     */
    loadEngineWorker(videoFxAssetParams) {
        return __awaiter(this, void 0, void 0, function* () {
            // The engine worker will always be a required asset for the VideoFxProcessor
            try {
                // Determine engine worker path from versioning of the SDK worker
                const engineWorkerPath = this.getPathFromVideoFxAssetParams(this.videoFxSpec.paths.cdnBasePath + this.videoFxSpec.paths.workerPath, videoFxAssetParams);
                // Load the worker that will communicate with the VideoFxEngine
                this.engineWorker = yield loader_1.loadWorker(engineWorkerPath, 'VideoFxEngineWorker', {}, null);
                this.logger.info(`Successfully loaded the VideoFxProcessor's engine worker`);
                // Configure a handler to deal with messages received form the engine worker
                this.engineWorker.addEventListener('message', event => this.engineWorkerReceiver(event));
            }
            catch (error) {
                this.logger.error(error.toString());
                throw new Error(`Failed to load the VideoFxProcessor's engine worker`);
            }
        });
    }
    /**
     * Build the videoFxEngine.
     * @param videoFxAssetParams [[VideoFxAssetParams]] defining current version of SDK
     */
    buildEngine(videoFxAssetParams) {
        return __awaiter(this, void 0, void 0, function* () {
            // Instantiate the deferred promise so we can wait for the worker to
            // return a completion message
            this.buildEnginePromise = new DeferredPromise_1.DeferredPromise();
            // Send a message via the engine worker to instantiate
            // the video fx engine
            this.engineWorker.postMessage({
                msg: VideoFxConstants_1.WORKER_MSG.BUILD_ENGINE_REQUEST,
                payload: {
                    cdnBasePath: this.videoFxSpec.paths.cdnBasePath,
                    sdkVersioningParams: videoFxAssetParams,
                },
            });
            // Wait until the engine finishes building
            try {
                yield this.buildEnginePromise.getPromise();
            }
            catch (error) {
                this.logger.error(error.toString());
                throw new Error(`Failed to instantiate the VideoFxEngine`);
            }
        });
    }
    /**
     * Loads the Video Fx library to drive video post-processing, given the versioning
     * of the SDK worker from the VideoFxAssetParams interface passed as a parameter.
     * @param videoFxAssetParams
     */
    loadFxLib(videoFxAssetParams) {
        return __awaiter(this, void 0, void 0, function* () {
            // Determine engine worker path from versioning of the SDK worker
            const fxLibPath = this.getPathFromVideoFxAssetParams(this.videoFxSpec.paths.cdnBasePath + this.videoFxSpec.paths.fxLibPath, videoFxAssetParams);
            const WORKER_FETCH_OPTIONS = {
                method: 'GET',
                mode: 'cors',
                credentials: 'omit',
                redirect: 'follow',
                referrerPolicy: 'no-referrer',
            };
            try {
                const res = yield fetch_1.fetchWithBehavior(fxLibPath, WORKER_FETCH_OPTIONS, {});
                if (!res.ok) {
                    throw new Error('Fetch failed.');
                }
                const blobURL = window.URL.createObjectURL(yield res.blob());
                yield new Promise((resolve, reject) => {
                    this.fxLibScript = document.createElement('script');
                    this.fxLibScript.setAttribute('src', blobURL);
                    this.fxLibScript.setAttribute('type', 'module');
                    this.fxLibScript.setAttribute('async', 'false');
                    this.fxLibScript.addEventListener('load', resolve);
                    this.fxLibScript.addEventListener('error', reject);
                    document.body.appendChild(this.fxLibScript);
                });
            }
            catch (error) {
                this.logger.error(error.toString());
                throw new Error(`Failed to load the fxlib`);
            }
        });
    }
    /**
     * Getter for the current [[VideoFxConfig]] maintained as an instance property of
     * [[VideoFxProcessor]].
     * @returns currentEffectConfig
     */
    getEffectConfig() {
        return this.cloneConfigFrom(this.effectConfig);
    }
    /**
     * Receives messages from the engine worker and then delegates
     * the proper response to a different function.
     * @param event notification to be received from the engine worker
     */
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    engineWorkerReceiver(event) {
        const msg = event.data;
        switch (msg.msg) {
            case VideoFxConstants_1.WORKER_MSG.BUILD_ENGINE_RESPONSE:
                this.settleEngineBuildPromise(msg.payload);
                break;
            case VideoFxConstants_1.WORKER_MSG.PERFORM_SEGMENTATION_RESPONSE:
                this.settleSegmentationPromise(msg.payload.output);
                break;
            case VideoFxConstants_1.WORKER_MSG.PERFORM_SEGMENTATION_SAB_RESPONSE:
                this.settleSegmentationPromiseSAB();
                break;
            case VideoFxConstants_1.WORKER_MSG.DESTROY_ASSETS_RESPONSE:
                this.destroyedAssetsPromise.resolvePromise();
                break;
            default:
                this.logger.info(`VideoFx worker received unknown event msg: ${JSON.stringify(msg)}`);
                break;
        }
    }
    /**
     * Handle the message returned from the VideoFX Engine worker to
     * settle (resolve/reject) the promise associated with initializing the engine.
     * @param buildStatus status of the final result of building the engine
     */
    settleEngineBuildPromise(buildStatus) {
        // Resolve or reject the engineInstantiatedPromise depending on success
        // of instatiation
        if (buildStatus !== VideoFxConstants_1.SEGMENTATION_MODEL.LOAD_SUCCESS) {
            this.buildEnginePromise.rejectPromise(new Error(`Failed to build VideoFxProcessor's engine`));
        }
        else {
            this.logger.info(`Successfully built the VideoFxEngine`);
            this.buildEnginePromise.resolvePromise();
        }
    }
    /**
     * Handle the received segmentation mask and then resolve/reject the promise to notify
     * the main processing function to prepare for the next frame (using ImageData transfer).
     * @param segmentationMask
     */
    settleSegmentationPromise(segmentationMask) {
        // Resolve or reject the frameRequestPromise depending on the success of transforming
        // the input image
        if (segmentationMask) {
            // Resolve segmentation promise with mask data
            this.segmentationRequestPromise.resolveAndReplacePromise(segmentationMask);
        }
        else {
            this.segmentationRequestPromise.rejectAndReplacePromise(new Error(`Failed to perform a segmentation on the input image`));
        }
    }
    /**
     * Handle the received segmentation mask and then resolve/reject the promise to notify
     * the main processing function to prepare for the next frame (using shared array buffer).
     */
    settleSegmentationPromiseSAB() {
        try {
            // Resolve segmentation promise with mask data
            const transformedImageData = new ImageData(new Uint8ClampedArray(this.sharedImageData), VideoFxConstants_1.SEGMENTATION_MODEL.WIDTH_IN_PIXELS, VideoFxConstants_1.SEGMENTATION_MODEL.HEIGHT_IN_PIXELS);
            this.segmentationRequestPromise.resolveAndReplacePromise(transformedImageData);
        }
        catch (_a) {
            this.segmentationRequestPromise.rejectAndReplacePromise(new Error(`Failed to perform a segmentation with a shared ` + `array buffer on the input image`));
        }
    }
    /**
     * Function that will convert the VideoFxProcessor into a NoOp version of itself.
     * Will only return input video stream and not use worker, engine, or segmentation
     * model.
     */
    setToNoOpProcess() {
        this.process = this.noOpProcess;
    }
    /**
     * Detect client environment to determine if the [[VideoFxProcessor]] is supported.
     * @param logger to record/report events of checking processor support
     * @param attemptAssetLoad will also fetch and build all relevant components of the
     * processor to ensure end to end feature is supported
     * @returns a boolean promise that will resolve to true if supported and false if not
     */
    static isSupported(logger = new NoOpLogger_1.default(), attemptAssetLoad = true) {
        return __awaiter(this, void 0, void 0, function* () {
            // allCheckedPassed represents the state of support and we assume it is true until checkEnv tells us otherwise
            let allCheckedPassed = true;
            // checkEnv evaluates a boolean condition, badPromiseCondition, that when true would cause isSupported to fail.
            // We also log a corresponding error message for each support check so a builder can see what is still needed
            // in their environment.
            const checkEnv = (badPromiseCondition, message) => {
                if (badPromiseCondition) {
                    logger.info(message);
                    allCheckedPassed = false;
                }
            };
            // Get context for operating environment
            // could not figure out how to remove globalThis to test failure case
            /* istanbul ignore next */
            checkEnv(typeof globalThis === 'undefined', 'Browser does not have globalThis.');
            // Check workers are supported
            checkEnv(!support_1.supportsWorker(globalThis, logger), 'Browser does not support web workers.');
            // Check wasm is supported
            checkEnv(!support_1.supportsWASM(globalThis, logger), 'Browser does not support wasm.');
            // Check webgl2 is supported
            checkEnv(!document.createElement('canvas').getContext('webgl2'), 'Browser does not support webgl.');
            // Check browser support
            const browserBehavior = new DefaultBrowserBehavior_1.default();
            checkEnv(!browserBehavior.isVideoFxSupportedBrowser(), 'Browser is unsupported for VideoFxProcessor');
            // checkProcessor first checks if we can load all required assets and then tests VideoFxProcessor.
            const checkProcessor = () => __awaiter(this, void 0, void 0, function* () {
                if (attemptAssetLoad) {
                    try {
                        const testFxProcessor = new VideoFxProcessor(logger);
                        yield testFxProcessor.loadAssets();
                        yield testFxProcessor.destroy(); // destroy assets we just temp loaded
                    }
                    catch (_a) {
                        logger.info('Browser environment is unable to access the required external assets.');
                        return Promise.resolve(false);
                    }
                }
                return Promise.resolve(true);
            });
            return Promise.resolve(allCheckedPassed ? yield checkProcessor() : false);
        });
    }
    /**
     * Create a [[VideoFxProcessor]] that has loaded its necessary components, ready to instantly
     * process a video stream with the effects specified in the passed [[VideoFxConfig]].
     *
     * ** NOTICE **
     *
     * Amazon Chime background blur 2.0 and background replacement 2.0
     * Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.
     *
     * By installing or using this package, you agree to the AWS Customer Agreement, AWS Service Terms, and AWS Privacy Notice.
     * If you already have an AWS Customer Agreement, you agree that the terms of that agreement govern your download and use of this package.
     * This package is provided as AWS Content and subject to the AWS Customer agreement and any other agreement with AWS governing your use of
     * AWS services.
     */
    static create(logger, effectConfig, processingBudgetPerFrame = VideoFxConstants_1.RESOURCE_CONSTRAINTS.DEFAULT_PROCESSING_BUDGET_PER_FRAME, spec) {
        return __awaiter(this, void 0, void 0, function* () {
            // Create the videoFxProcessor
            const videoFxProcessor = new VideoFxProcessor(logger, processingBudgetPerFrame);
            if (spec) {
                videoFxProcessor.setVideoFxSpec(spec);
            }
            // Load the required assets and set desired effect config
            try {
                yield videoFxProcessor.loadAssets();
                yield videoFxProcessor.setEffectConfig(effectConfig);
                return videoFxProcessor;
            }
            catch (error) {
                logger.error(error.toString());
                // If we fail loading an essential asset from above, we overwrite our
                // processor to process with no operations or effects
                videoFxProcessor.setToNoOpProcess();
                throw new Error(`VideoFxProcessor built with support for only NoOp processing`);
            }
        });
    }
    /** @internal */
    setEventController(eventController) {
        /*
        if this is a first time we set the eventController, need to publish the current VideoFxConfig.
        Otherwise, just set the eventController.
        */
        if (this.eventController) {
            this.eventController = eventController;
        }
        else {
            this.eventController = eventController;
            this.publishVideoFxConfigEvent();
        }
    }
    publishVideoFxConfigEvent() {
        const mediaFXEventAttibutes = {
            backgroundBlurEnabled: this.effectConfig.backgroundBlur.isEnabled.toString(),
            backgroundBlurStrength: this.effectConfig.backgroundBlur.strength,
            backgroundReplacementEnabled: this.effectConfig.backgroundReplacement.isEnabled.toString(),
            backgroundFilterVersion: 2,
        };
        this.eventController.publishEvent('backgroundFilterConfigSelected', mediaFXEventAttibutes);
    }
    sameVideoFxConfig(firstConfig, secondConfig) {
        return (firstConfig.backgroundBlur.isEnabled === secondConfig.backgroundBlur.isEnabled &&
            firstConfig.backgroundBlur.strength === secondConfig.backgroundBlur.strength &&
            firstConfig.backgroundReplacement.backgroundImageURL ===
                secondConfig.backgroundReplacement.backgroundImageURL &&
            firstConfig.backgroundReplacement.defaultColor ===
                secondConfig.backgroundReplacement.defaultColor &&
            firstConfig.backgroundReplacement.isEnabled === secondConfig.backgroundReplacement.isEnabled);
    }
}
exports.default = VideoFxProcessor;
VideoFxProcessor.isSharedArrayBufferSupported = typeof SharedArrayBuffer !== 'undefined';
//# sourceMappingURL=VideoFxProcessor.js.map