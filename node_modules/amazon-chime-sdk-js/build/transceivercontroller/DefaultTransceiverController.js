"use strict";
// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
// SPDX-License-Identifier: Apache-2.0
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const AudioProfile_1 = __importDefault(require("../audioprofile/AudioProfile"));
const RedundantAudioRecoveryMetricReport_1 = __importDefault(require("../clientmetricreport/RedundantAudioRecoveryMetricReport"));
const RedundantAudioEncoder_1 = __importDefault(require("../redundantaudioencoder/RedundantAudioEncoder"));
const RedundantAudioEncoderWorkerCode_1 = __importDefault(require("../redundantaudioencoderworkercode/RedundantAudioEncoderWorkerCode"));
const AsyncScheduler_1 = __importDefault(require("../scheduler/AsyncScheduler"));
class DefaultTransceiverController {
    constructor(logger, browserBehavior, meetingSessionContext) {
        this.logger = logger;
        this.browserBehavior = browserBehavior;
        this.meetingSessionContext = meetingSessionContext;
        this._localCameraTransceiver = null;
        this._localAudioTransceiver = null;
        this.videoSubscriptions = [];
        this.defaultMediaStream = null;
        this.peer = null;
        this.streamIdToTransceiver = new Map();
        this.groupIdToTransceiver = new Map();
        this.audioRedWorker = null;
        this.audioRedWorkerURL = null;
        this.audioMetricsHistory = new Array();
        this.redMetricsObservers = new Set();
        this.currentNumRedundantEncodings = 0;
        this.lastRedHolddownTimerStartTimestampMs = 0;
        this.lastHighPacketLossEventTimestampMs = 0;
        this.lastAudioRedTurnOffTimestampMs = 0;
        this.maxAudioMetricsHistory = 20;
        this.audioRedPacketLossShortEvalPeriodMs = 5 * 1000; // 5s
        this.audioRedPacketLossLongEvalPeriodMs = 15 * 1000; // 15s
        this.audioRedHoldDownTimeMs = 5 * 60 * 1000; // 5m
        this.redRecoveryTimeMs = 1 * 60 * 1000; // 1m
    }
    setEncodingParameters(encodingParamMap) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this._localCameraTransceiver || this._localCameraTransceiver.direction !== 'sendrecv') {
                return;
            }
            const sender = this._localCameraTransceiver.sender;
            if (!encodingParamMap || encodingParamMap.size === 0) {
                return;
            }
            const newEncodingParams = Array.from(encodingParamMap.values());
            const oldParam = sender.getParameters();
            if (!oldParam.encodings || oldParam.encodings.length === 0) {
                oldParam.encodings = newEncodingParams;
            }
            else {
                for (const existing of oldParam.encodings) {
                    for (const changed of newEncodingParams) {
                        if ((existing.rid || changed.rid) && existing.rid !== changed.rid) {
                            continue;
                        }
                        let key;
                        for (key in changed) {
                            // These properties can't be changed.
                            if (key === 'rid' || key === 'codecPayloadType') {
                                continue;
                            }
                            /* istanbul ignore else */
                            if (changed.hasOwnProperty(key)) {
                                existing[key] = changed[key];
                            }
                        }
                    }
                }
            }
            yield sender.setParameters(oldParam);
        });
    }
    localAudioTransceiver() {
        return this._localAudioTransceiver;
    }
    localVideoTransceiver() {
        return this._localCameraTransceiver;
    }
    setVideoSendingBitrateKbps(bitrateKbps) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this._localCameraTransceiver || this._localCameraTransceiver.direction !== 'sendrecv') {
                return;
            }
            const sender = this._localCameraTransceiver.sender;
            if (!sender || bitrateKbps <= 0) {
                return;
            }
            const param = sender.getParameters();
            if (!param.encodings) {
                param.encodings = [{}];
            }
            for (const encodeParam of param.encodings) {
                encodeParam.maxBitrate = bitrateKbps * 1000;
            }
            yield sender.setParameters(param);
        });
    }
    setPeer(peer) {
        this.peer = peer;
    }
    reset() {
        this.destroyAudioRedWorkerAndStates();
        this._localCameraTransceiver = null;
        this._localAudioTransceiver = null;
        this.videoSubscriptions = [];
        this.defaultMediaStream = null;
        this.peer = null;
    }
    useTransceivers() {
        return !!this.peer && typeof this.peer.getTransceivers !== 'undefined';
    }
    hasVideoInput() {
        if (!this._localCameraTransceiver || this._localCameraTransceiver.direction !== 'sendrecv')
            return false;
        return true;
    }
    trackIsVideoInput(track) {
        if (!this._localCameraTransceiver) {
            return false;
        }
        return (track === this._localCameraTransceiver.sender.track ||
            track === this._localCameraTransceiver.receiver.track);
    }
    setupLocalTransceivers() {
        var _a, _b;
        if (!this.useTransceivers()) {
            return;
        }
        if (!this.defaultMediaStream && typeof MediaStream !== 'undefined') {
            this.defaultMediaStream = new MediaStream();
        }
        if (!this._localAudioTransceiver) {
            this._localAudioTransceiver = this.peer.addTransceiver('audio', {
                direction: 'inactive',
                streams: [this.defaultMediaStream],
            });
            if ((_b = (_a = this.meetingSessionContext) === null || _a === void 0 ? void 0 : _a.audioProfile) === null || _b === void 0 ? void 0 : _b.hasRedundancyEnabled()) {
                // This will perform additional necessary setup for the audio transceiver.
                this.setupAudioRedWorker();
            }
        }
        if (!this._localCameraTransceiver) {
            this._localCameraTransceiver = this.addTransceiver('video', {
                direction: 'inactive',
                streams: [this.defaultMediaStream],
            });
        }
    }
    replaceAudioTrack(track) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this._localAudioTransceiver || this._localAudioTransceiver.direction !== 'sendrecv') {
                this.logger.info(`audio transceiver direction is not set up or not activated`);
                return false;
            }
            yield this._localAudioTransceiver.sender.replaceTrack(track);
            return true;
        });
    }
    setAudioInput(track) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.setTransceiverInput(this._localAudioTransceiver, track);
            return;
        });
    }
    setVideoInput(track) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.setTransceiverInput(this._localCameraTransceiver, track);
            return;
        });
    }
    updateVideoTransceivers(videoStreamIndex, videosToReceive) {
        if (!this.useTransceivers()) {
            return videosToReceive.array();
        }
        // See https://blog.mozilla.org/webrtc/rtcrtptransceiver-explored/ for details on transceivers
        const transceivers = this.peer.getTransceivers();
        // Subscription index 0 is reserved for transmitting camera.
        // We mark inactive slots with 0 in the subscription array.
        this.videoSubscriptions = [0];
        videosToReceive = videosToReceive.clone();
        this.updateTransceivers(transceivers, videoStreamIndex, videosToReceive);
        this.logger.debug(() => {
            return this.debugDumpTransceivers();
        });
        return this.videoSubscriptions;
    }
    updateTransceivers(transceivers, videoStreamIndex, videosToReceive) {
        const videosRemaining = videosToReceive.array();
        if (transceivers.length !== 0 && !transceivers[0].stop) {
            // This function and its usage can be removed once we raise Chrome browser requirements
            // to M88 (when `RTCRtpTransceiver.stop` was added)
            this.logger.info('Updating transceivers without `stop` function');
            this.updateTransceiverWithoutStop(transceivers, videoStreamIndex, videosRemaining);
        }
        else if (transceivers.length !== 0) {
            this.updateTransceiverWithStop(transceivers, videoStreamIndex, videosRemaining);
        }
        // Add transceivers for the remaining subscriptions
        for (const index of videosRemaining) {
            // @ts-ignore
            const transceiver = this.addTransceiver('video', {
                direction: 'recvonly',
                streams: [new MediaStream()],
            });
            this.streamIdToTransceiver.set(index, transceiver);
            this.groupIdToTransceiver.set(videoStreamIndex.groupIdForStreamId(index), transceiver);
            this.videoSubscriptions.push(index);
            this.logger.info(`adding transceiver mid: ${transceiver.mid} subscription: ${index} direction: recvonly`);
        }
    }
    updateTransceiverWithStop(transceivers, videoStreamIndex, videosRemaining) {
        // Begin counting out index in the the subscription array at 1 since the camera.
        // Always occupies position 0 (whether active or not).
        let n = 1;
        // Reset since otherwise there will be stale indexes corresponding to
        // stopped transceivers.
        this.videoSubscriptions = [0];
        for (const transceiver of transceivers) {
            if (transceiver === this._localCameraTransceiver ||
                !this.transceiverIsVideo(transceiver) ||
                !transceiver.mid) {
                continue;
            }
            let reusingTranceiver = false;
            // See if we want this existing transceiver for a simulcast stream switch
            //
            // By convention with the service backend, msid is equal to the media section mid, prefixed with the string "v_";
            // we use this to get the stream ID for the track
            const streamId = videoStreamIndex.streamIdForTrack('v_' + transceiver.mid);
            if (transceiver.direction !== 'inactive' && streamId !== undefined) {
                for (const [index, recvStreamId] of videosRemaining.entries()) {
                    // `streamId` may still be the same as `recvStreamId`
                    if (videoStreamIndex.StreamIdsInSameGroup(streamId, recvStreamId)) {
                        transceiver.direction = 'recvonly';
                        this.videoSubscriptions[n] = recvStreamId;
                        reusingTranceiver = true;
                        this.streamIdToTransceiver.delete(streamId);
                        this.streamIdToTransceiver.set(recvStreamId, transceiver);
                        videosRemaining.splice(index, 1);
                        break;
                    }
                }
            }
            if (!reusingTranceiver) {
                this.videoSubscriptions[n] = 0;
                this.logger.info(`Stopping MID: ${transceiver.mid}, direction: ${transceiver.direction}, current direction: ${transceiver.currentDirection}`);
                // Clean up transceiver and mappings for streams that have been unsubscribed from.  Note we do not try to reuse
                // old inactive transceivers for new streams as Firefox will reuse the last frame from
                // that transceiver, and additionally we simply don't want to risk wiring up a transceiver
                // to the incorrect video stream for no real benefit besides possible a smaller SDP size.
                transceiver.stop(); // Note (as of Firefox 94): Firefox will keep these around forever
                for (const [streamId, previousTransceiver] of this.streamIdToTransceiver.entries()) {
                    if (transceiver.mid === previousTransceiver.mid) {
                        this.streamIdToTransceiver.delete(streamId);
                        this.groupIdToTransceiver.delete(videoStreamIndex.groupIdForStreamId(streamId));
                    }
                }
            }
            n += 1;
        }
    }
    // This function operates similarily to `updateTransceiverWithStop` with the following changes to account
    // for the fact RTCRtpTransceiver.stop is not available on all supported browsers:
    //  * We attempt to reuse inactive transceivers because libwebrtc will not remove them otherwise and
    //    the SDP will grow endlessly.
    //  * We mark unsubscribed transceivers as 'inactive' so that they can be reused. This requires using a
    //    second for loop.
    updateTransceiverWithoutStop(transceivers, videoStreamIndex, videosRemaining) {
        let n = 1;
        for (const transceiver of transceivers) {
            if (transceiver === this._localCameraTransceiver || !this.transceiverIsVideo(transceiver)) {
                continue;
            }
            this.videoSubscriptions[n] = 0;
            if (transceiver.direction !== 'inactive') {
                const streamId = videoStreamIndex.streamIdForTrack('v_' + transceiver.mid);
                if (streamId !== undefined) {
                    for (const [index, recvStreamId] of videosRemaining.entries()) {
                        if (videoStreamIndex.StreamIdsInSameGroup(streamId, recvStreamId)) {
                            transceiver.direction = 'recvonly';
                            this.videoSubscriptions[n] = recvStreamId;
                            this.streamIdToTransceiver.delete(streamId);
                            this.streamIdToTransceiver.set(recvStreamId, transceiver);
                            videosRemaining.splice(index, 1);
                            break;
                        }
                    }
                }
            }
            n += 1;
        }
        // Next fill in open slots and remove unused
        n = 1;
        for (const transceiver of transceivers) {
            if (transceiver === this._localCameraTransceiver || !this.transceiverIsVideo(transceiver)) {
                continue;
            }
            if (transceiver.direction === 'inactive' && videosRemaining.length > 0) {
                // Fill available slot
                transceiver.direction = 'recvonly';
                const streamId = videosRemaining.shift();
                this.videoSubscriptions[n] = streamId;
                this.streamIdToTransceiver.set(streamId, transceiver);
                this.groupIdToTransceiver.set(videoStreamIndex.groupIdForStreamId(streamId), transceiver);
            }
            else {
                // Remove if no longer subscribed
                if (this.videoSubscriptions[n] === 0) {
                    transceiver.direction = 'inactive';
                    for (const [streamId, previousTransceiver] of this.streamIdToTransceiver.entries()) {
                        if (transceiver === previousTransceiver) {
                            this.streamIdToTransceiver.delete(streamId);
                            this.groupIdToTransceiver.delete(videoStreamIndex.groupIdForStreamId(streamId));
                        }
                    }
                }
            }
            n += 1;
        }
    }
    getMidForStreamId(streamId) {
        var _a;
        return (_a = this.streamIdToTransceiver.get(streamId)) === null || _a === void 0 ? void 0 : _a.mid;
    }
    setStreamIdForMid(mid, newStreamId) {
        for (const [streamId, transceiver] of this.streamIdToTransceiver.entries()) {
            if (transceiver.mid === mid) {
                this.streamIdToTransceiver.delete(streamId);
                this.streamIdToTransceiver.set(newStreamId, transceiver);
                return;
            }
        }
    }
    getMidForGroupId(groupId) {
        var _a, _b;
        return (_b = (_a = this.groupIdToTransceiver.get(groupId)) === null || _a === void 0 ? void 0 : _a.mid) !== null && _b !== void 0 ? _b : undefined;
    }
    transceiverIsVideo(transceiver) {
        return ((transceiver.receiver &&
            transceiver.receiver.track &&
            transceiver.receiver.track.kind === 'video') ||
            (transceiver.sender && transceiver.sender.track && transceiver.sender.track.kind === 'video'));
    }
    debugDumpTransceivers() {
        let msg = '';
        let n = 0;
        for (const transceiver of this.peer.getTransceivers()) {
            if (!this.transceiverIsVideo(transceiver)) {
                continue;
            }
            msg += `transceiver index=${n} mid=${transceiver.mid} subscription=${this.videoSubscriptions[n]} direction=${transceiver.direction}\n`;
            n += 1;
        }
        return msg;
    }
    setTransceiverInput(transceiver, track) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!transceiver) {
                return;
            }
            if (track) {
                transceiver.direction = 'sendrecv';
            }
            else {
                transceiver.direction = 'inactive';
            }
            yield transceiver.sender.replaceTrack(track);
        });
    }
    forEachRedMetricsObserver(redMetricReport) {
        for (const observer of this.redMetricsObservers) {
            AsyncScheduler_1.default.nextTick(() => {
                /* istanbul ignore else */
                // Since this executes asynchronously, we need to check if the observer has not been removed.
                if (this.redMetricsObservers.has(observer)) {
                    observer.recoveryMetricsDidReceive(redMetricReport);
                }
            });
        }
    }
    disableAudioRedundancy() {
        // Reset the audio profile with the configured bitrate and force redundancy to be false.
        this.meetingSessionContext.audioProfile = new AudioProfile_1.default(this.meetingSessionContext.audioProfile.audioBitrateBps, false);
        this.meetingSessionContext.audioVideoController.setAudioProfile(this.meetingSessionContext.audioProfile);
    }
    setupAudioRedWorker() {
        var _a, _b;
        // @ts-ignore
        const supportsRTCScriptTransform = !!window.RTCRtpScriptTransform;
        // @ts-ignore
        const supportsInsertableStreams = !!RTCRtpSender.prototype.createEncodedStreams;
        if (supportsRTCScriptTransform) {
            // This is the prefered approach according to
            // https://github.com/w3c/webrtc-encoded-transform/blob/main/explainer.md.
            this.logger.info('[AudioRed] Supports encoded insertable streams using RTCRtpScriptTransform');
        }
        else if (supportsInsertableStreams) {
            this.logger.info('[AudioRed] Supports encoded insertable streams using TransformStream');
        }
        else {
            this.disableAudioRedundancy();
            // We need to recreate the peer connection without encodedInsertableStreams in the
            // peer connection config otherwise we would need to create pass through transforms
            // for all media streams. Throwing the error here and having AttackMediaInputTask throw the
            // error again will result in a full reconnect.
            throw new Error('[AudioRed] Encoded insertable streams not supported. Recreating peer connection with audio redundancy disabled.');
        }
        // Run the entire redundant audio worker setup in a `try` block to allow any errors to trigger a reconnect with
        // audio redundancy disabled.
        try {
            this.audioRedWorkerURL = URL.createObjectURL(new Blob([RedundantAudioEncoderWorkerCode_1.default], {
                type: 'application/javascript',
            }));
            this.logger.info(`[AudioRed] Redundant audio worker URL ${this.audioRedWorkerURL}`);
            this.audioRedWorker = new Worker(this.audioRedWorkerURL);
        }
        catch (error) {
            this.logger.error(`[AudioRed] Unable to create audio red worker due to ${error}`);
            URL.revokeObjectURL(this.audioRedWorkerURL);
            this.audioRedWorkerURL = null;
            this.audioRedWorker = null;
            this.disableAudioRedundancy();
            this.logger.info(`[AudioRed] Recreating peer connection with audio redundancy disabled`);
            // We need to recreate the peer connection without encodedInsertableStreams in the
            // peer connection config otherwise we would need to create pass through transforms
            // for all media streams. Throwing the error here and having AttackMediaInputTask throw the
            // error again will result in a full reconnect.
            throw error;
        }
        this.audioRedEnabled = true;
        // We cannot use console.log in production code and we cannot
        // transfer the logger object so we need the worker to post messages
        // to the main thread for logging
        this.audioRedWorker.onmessage = (event) => {
            /* istanbul ignore else */
            if (event.data.type === 'REDWorkerLog') {
                this.logger.info(event.data.log);
            } /* istanbul ignore next */
            else if (event.data.type === 'RedundantAudioEncoderStats') {
                const redMetricReport = new RedundantAudioRecoveryMetricReport_1.default();
                redMetricReport.currentTimestampMs = Date.now();
                redMetricReport.ssrc = event.data.ssrc;
                redMetricReport.totalAudioPacketsLost = event.data.totalAudioPacketsLost;
                redMetricReport.totalAudioPacketsExpected = event.data.totalAudioPacketsExpected;
                redMetricReport.totalAudioPacketsRecoveredRed = event.data.totalAudioPacketsRecoveredRed;
                redMetricReport.totalAudioPacketsRecoveredFec = event.data.totalAudioPacketsRecoveredFec;
                this.forEachRedMetricsObserver(redMetricReport);
            }
        };
        if (supportsRTCScriptTransform) {
            // @ts-ignore
            this._localAudioTransceiver.sender.transform = new RTCRtpScriptTransform(this.audioRedWorker, { type: 'SenderTransform' });
            // @ts-ignore
            this._localAudioTransceiver.receiver.transform = new RTCRtpScriptTransform(this.audioRedWorker, { type: 'ReceiverTransform' });
            // eslint-disable-next-line
        }
        else /* istanbul ignore else */ if (supportsInsertableStreams) {
            // @ts-ignore
            const sendStreams = this._localAudioTransceiver.sender.createEncodedStreams();
            // @ts-ignore
            const receiveStreams = this._localAudioTransceiver.receiver.createEncodedStreams();
            this.audioRedWorker.postMessage({
                msgType: 'StartRedWorker',
                send: sendStreams,
                receive: receiveStreams,
            }, [
                sendStreams.readable,
                sendStreams.writable,
                receiveStreams.readable,
                receiveStreams.writable,
            ]);
        }
        /* istanbul ignore next */
        (_a = this.meetingSessionContext) === null || _a === void 0 ? void 0 : _a.audioVideoController.addObserver(this);
        /* istanbul ignore next */
        this.addRedundantAudioRecoveryMetricsObserver((_b = this.meetingSessionContext) === null || _b === void 0 ? void 0 : _b.statsCollector);
    }
    /**
     * Adds a transceiver to the peer connection and performs additional necessary setup.
     */
    addTransceiver(trackOrKind, init) {
        var _a;
        const transceiver = this.peer.addTransceiver(trackOrKind, init);
        // @ts-ignore
        // Transforms need to be setup for every transceiver to allow media flow for the given transceiver if WebRTC Encoded
        // Transform (https://github.com/w3c/webrtc-encoded-transform/blob/main/explainer.md) is used.
        if (!((_a = this.peer.getConfiguration()) === null || _a === void 0 ? void 0 : _a.encodedInsertableStreams) || !this.audioRedWorker)
            return transceiver;
        // @ts-ignore
        const supportsRTCScriptTransform = !!window.RTCRtpScriptTransform;
        // @ts-ignore
        const supportsInsertableStreams = !!RTCRtpSender.prototype.createEncodedStreams;
        if (supportsRTCScriptTransform) {
            // @ts-ignore
            transceiver.sender.transform = new RTCRtpScriptTransform(this.audioRedWorker, {
                type: 'PassthroughTransform',
            });
            // @ts-ignore
            transceiver.receiver.transform = new RTCRtpScriptTransform(this.audioRedWorker, {
                type: 'PassthroughTransform',
            });
            // eslint-disable-next-line
        }
        else /* istanbul ignore else */ if (supportsInsertableStreams) {
            // @ts-ignore
            const sendStreams = transceiver.sender.createEncodedStreams();
            // @ts-ignore
            const receiveStreams = transceiver.receiver.createEncodedStreams();
            this.audioRedWorker.postMessage({
                msgType: 'PassthroughTransform',
                send: sendStreams,
                receive: receiveStreams,
            }, [
                sendStreams.readable,
                sendStreams.writable,
                receiveStreams.readable,
                receiveStreams.writable,
            ]);
        }
        return transceiver;
    }
    destroyAudioRedWorkerAndStates() {
        var _a, _b;
        if (this.audioRedWorker) {
            URL.revokeObjectURL(this.audioRedWorkerURL);
            this.audioRedWorkerURL = null;
            this.audioRedWorker.terminate();
            this.audioRedWorker = null;
            this.currentNumRedundantEncodings = 0;
            this.lastRedHolddownTimerStartTimestampMs = 0;
            this.lastAudioRedTurnOffTimestampMs = 0;
            this.lastHighPacketLossEventTimestampMs = 0;
            this.audioRedEnabled = true;
            /* istanbul ignore next */
            (_a = this.meetingSessionContext) === null || _a === void 0 ? void 0 : _a.audioVideoController.removeObserver(this);
            /* istanbul ignore next */
            this.removeRedundantAudioRecoveryMetricsObserver((_b = this.meetingSessionContext) === null || _b === void 0 ? void 0 : _b.statsCollector);
        }
    }
    setAudioPayloadTypes(payloadTypeMap) {
        if (this.audioRedWorker) {
            this.audioRedWorker.postMessage({
                msgType: 'RedPayloadType',
                payloadType: payloadTypeMap.get('red'),
            });
            this.audioRedWorker.postMessage({
                msgType: 'OpusPayloadType',
                payloadType: payloadTypeMap.get('opus'),
            });
        }
    }
    metricsDidReceive(clientMetricReport) {
        const { currentTimestampMs } = clientMetricReport;
        const rtcStatsReport = clientMetricReport.getRTCStatsReport();
        let receiverReportReceptionTimestampMs = 0;
        let currentTotalPacketsSent = 0;
        let currentTotalPacketsLost = 0;
        rtcStatsReport.forEach(report => {
            /* istanbul ignore else */
            if (report.kind === 'audio') {
                /* istanbul ignore else */
                if (report.type === 'outbound-rtp') {
                    currentTotalPacketsSent = report.packetsSent;
                } /* istanbul ignore else */
                else if (report.type === 'remote-inbound-rtp') {
                    // Use the timestamp that the receiver report was received on the client side to get a more accurate time
                    // interval for the metrics.
                    receiverReportReceptionTimestampMs = report.timestamp;
                    currentTotalPacketsLost = report.packetsLost;
                }
            }
        });
        // Since the timestamp from the server side is only updated when a new receiver report is generated, only add
        // metrics with new timestamps to our metrics history.
        //
        // Also, make sure that the total packets sent is greater than the most recent value in the history before consuming
        // to avoid divide-by-zero while calculating uplink loss percent.
        if (this.audioMetricsHistory.length === 0 ||
            (receiverReportReceptionTimestampMs >
                this.audioMetricsHistory[this.audioMetricsHistory.length - 1].timestampMs &&
                currentTotalPacketsSent >
                    this.audioMetricsHistory[this.audioMetricsHistory.length - 1].totalPacketsSent)) {
            // Note that although the total packets sent is updated anytime we get the WebRTC stats, we are only adding a new
            // metric for total packets sent when we receive a new receiver report. We only care about the total packets that
            // the server was expected to receive at the time that the latest `packetsLost` metric was calculated in order to
            // do our uplink loss calculation. Therefore, we only record the total packets sent when we receive a new receiver
            // report, which will give us an estimate of the number of packets that the server was supposed to receive at the
            // time when the latest `packetsLost` metric was calculated.
            this.audioMetricsHistory.push({
                timestampMs: receiverReportReceptionTimestampMs,
                totalPacketsSent: currentTotalPacketsSent,
                totalPacketsLost: currentTotalPacketsLost,
            });
        }
        // Remove the oldest metric report from our list
        if (this.audioMetricsHistory.length > this.maxAudioMetricsHistory) {
            this.audioMetricsHistory.shift();
        }
        // As the minimum RTCP frequency is about 1 every 5 seconds,
        // we are limited to using a minimum timewindow of 5 seconds.
        // This is because the cumulative packetsLost metric remains
        // the same for 5 consecutive client metric reports.
        const lossPercent5sTimewindow = this.lossPercent(this.audioRedPacketLossShortEvalPeriodMs);
        const lossPercent15sTimewindow = this.lossPercent(this.audioRedPacketLossLongEvalPeriodMs);
        // Taking the max loss percent between a short and long time window will allow
        // us to increase the number of encodings fast but will slowly decrease the
        // number of encodings on loss recovery.
        const maxLossPercent = Math.max(lossPercent5sTimewindow, lossPercent15sTimewindow);
        const [newNumRedundantEncodings, shouldTurnOffRed,] = RedundantAudioEncoder_1.default.getNumRedundantEncodingsForPacketLoss(maxLossPercent);
        if (shouldTurnOffRed) {
            this.lastHighPacketLossEventTimestampMs = currentTimestampMs;
            /* istanbul ignore next */
            if (this.audioRedEnabled) {
                if (this.audioRedWorker) {
                    this.audioRedWorker.postMessage({
                        msgType: 'Disable',
                    });
                }
                this.audioRedEnabled = false;
                this.lastAudioRedTurnOffTimestampMs = currentTimestampMs;
            }
            return;
        }
        else if (!this.audioRedEnabled) {
            const timeSinceRedOff = currentTimestampMs - this.lastAudioRedTurnOffTimestampMs;
            const timeSinceLastHighPacketLossEvent = currentTimestampMs - this.lastHighPacketLossEventTimestampMs;
            if (timeSinceRedOff >= this.audioRedPacketLossLongEvalPeriodMs &&
                timeSinceLastHighPacketLossEvent < this.redRecoveryTimeMs) {
                // This is probably not a transient high packet loss spike.
                // We need to turn off RED for awhile to avoid congestion collapse.
                return;
            }
            else {
                // Enable red as we've completed the recovery wait time.
                /* istanbul ignore next */
                if (this.audioRedWorker) {
                    this.audioRedWorker.postMessage({
                        msgType: 'Enable',
                    });
                }
                this.audioRedEnabled = true;
                this.maybeResetHoldDownTimer(currentTimestampMs);
            }
        }
        if (this.shouldUpdateAudioRedWorkerEncodings(currentTimestampMs, newNumRedundantEncodings)) {
            /* istanbul ignore next */
            if (this.audioRedWorker) {
                this.audioRedWorker.postMessage({
                    msgType: 'UpdateNumRedundantEncodings',
                    numRedundantEncodings: newNumRedundantEncodings,
                });
            }
        }
    }
    maybeResetHoldDownTimer(currentTimestampMs) {
        if (this.currentNumRedundantEncodings > 0) {
            this.lastRedHolddownTimerStartTimestampMs = currentTimestampMs;
        }
    }
    lossPercent(timeWindowMs) {
        if (this.audioMetricsHistory.length < 2) {
            return 0;
        }
        const latestReceiverReportTimestampMs = this.audioMetricsHistory[this.audioMetricsHistory.length - 1].timestampMs;
        const currentTotalPacketsSent = this.audioMetricsHistory[this.audioMetricsHistory.length - 1].totalPacketsSent;
        const currentTotalPacketsLost = this.audioMetricsHistory[this.audioMetricsHistory.length - 1].totalPacketsLost;
        // Iterate backwards in the metrics history, from the report immediately preceeding
        // the latest one, until we find the first metric report whose timestamp differs
        // from the latest report by atleast timeWindowMs
        for (let i = this.audioMetricsHistory.length - 2; i >= 0; i--) {
            if (latestReceiverReportTimestampMs - this.audioMetricsHistory[i].timestampMs >=
                timeWindowMs) {
                const lossDelta = currentTotalPacketsLost - this.audioMetricsHistory[i].totalPacketsLost;
                const sentDelta = currentTotalPacketsSent - this.audioMetricsHistory[i].totalPacketsSent;
                const lossPercent = 100 * (lossDelta / sentDelta);
                return Math.max(0, Math.min(lossPercent, 100));
            }
        }
        // If we are here, we don't have enough entries in history
        // to calculate the loss for the given time window
        return 0;
    }
    shouldUpdateAudioRedWorkerEncodings(currentTimestampMs, newNumRedundantEncodings) {
        // If newNumRedundantEncodings is the same as the current
        // then we don't need to send a message to the red worker.
        if (this.currentNumRedundantEncodings === newNumRedundantEncodings) {
            this.maybeResetHoldDownTimer(currentTimestampMs);
            return false;
        }
        // If newNumRedundantEncodings is less than the current
        // check if we've cleared the hold down time and only
        // then allow the update to be sent to the red worker
        if (newNumRedundantEncodings < this.currentNumRedundantEncodings &&
            currentTimestampMs - this.lastRedHolddownTimerStartTimestampMs < this.audioRedHoldDownTimeMs) {
            return false;
        }
        this.currentNumRedundantEncodings = newNumRedundantEncodings;
        this.maybeResetHoldDownTimer(currentTimestampMs);
        return true;
    }
    addRedundantAudioRecoveryMetricsObserver(observer) {
        this.redMetricsObservers.add(observer);
    }
    removeRedundantAudioRecoveryMetricsObserver(observer) {
        this.redMetricsObservers.delete(observer);
    }
}
exports.default = DefaultTransceiverController;
//# sourceMappingURL=DefaultTransceiverController.js.map