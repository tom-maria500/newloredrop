{"version":3,"file":"AudioTransformDevice.js","sourceRoot":"","sources":["../../src/devicecontroller/AudioTransformDevice.ts"],"names":[],"mappings":";AAAA,qEAAqE;AACrE,sCAAsC;;;AAsDtC;;;;GAIG;AACH,gHAAgH;AAChH,SAAgB,sBAAsB,CAAC,MAAW;IAChD,OAAO,CACL,CAAC,CAAC,MAAM;QACR,OAAO,MAAM,KAAK,QAAQ;QAC1B,MAAM,IAAI,MAAM;QAChB,MAAM,IAAI,MAAM;QAChB,iBAAiB,IAAI,MAAM,CAC5B,CAAC;AACJ,CAAC;AARD,wDAQC","sourcesContent":["// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n\nimport AudioNodeSubgraph from './AudioNodeSubgraph';\nimport Device from './Device';\n\n/**\n * A device that applies some transform to another device, returning a device and optional\n * `AudioNode` for use by the device controller.\n *\n * The results are applied by the device controller in two stages:\n *\n * 1. The transform device is used to retrieve the constraints that identify an inner media stream.\n *    This will be managed by the controller.\n * 2. The transform device provides a Web Audio node that will be connected between the input and\n *    the output of the device controller's audio graph. This is returned as a pair, `(start, end)`,\n *    to allow an arbitrary subgraph of nodes to be returned.\n *\n * The application should call `stop` when the device will no longer be used. This method is\n * defined on this interface to establish that convention.\n */\nexport default interface AudioTransformDevice {\n  /**\n   * Called when `realtimeMuteLocalAudio` is called on the `RealtimeController`. Implement this\n   * callback to avoid doing expensive processing when the audio output is disabled.\n   */\n  mute(muted: boolean): Promise<void>;\n\n  /**\n   * `stop` should be called by the application to free any resources associated\n   * with the device (e.g., workers).\n   *\n   * After this is called, the device should be discarded.\n   */\n  stop(): Promise<void>;\n\n  /**\n   * Return the inner {@link Device} that the device controller should select as part\n   * of the application of this `AudioTransformDevice`.\n   */\n  intrinsicDevice(): Promise<Device>;\n\n  /**\n   * Optionally return a pair of `AudioNode`s that should be connected to the applied inner\n   * device. The two nodes can be the same, indicating the smallest possible subgraph.\n   *\n   * Each device can be used no more than once at a time in an audio graph. It is acceptable\n   * to reuse audio nodes for successive calls to `createAudioNode`, so long as the context\n   * does not differ.\n   *\n   * @param context The `AudioContext` to use when instantiating the nodes.\n   */\n  createAudioNode?(context: AudioContext): Promise<AudioNodeSubgraph | undefined>;\n}\n\n/**\n * `isAudioTransformDevice` is a type guard for {@link AudioTransformDevice}.\n *\n * @param device the value to check.\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any,@typescript-eslint/explicit-module-boundary-types\nexport function isAudioTransformDevice(device: any): device is AudioTransformDevice {\n  return (\n    !!device &&\n    typeof device === 'object' &&\n    'mute' in device &&\n    'stop' in device &&\n    'intrinsicDevice' in device\n  );\n}\n"]}